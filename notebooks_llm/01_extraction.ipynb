{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import eval_extraction\n",
    "import openai\n",
    "import extraction\n",
    "openai.api_key = open('/home/chansingh/.OPENAI_KEY').read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/data_clean.pkl\")[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"paper___url\",\n",
    "        \"paper___raw_text\",\n",
    "        \"paper___year\",\n",
    "        \"participants___male\",\n",
    "        \"participants___female\",\n",
    "        \"participants___total\",\n",
    "        \"participants___white\",\n",
    "        \"participants___black\",\n",
    "        \"participants___latino\",\n",
    "        \"participants___asian\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current outputs:\n",
    "- num_male, num_female, num_total, num_male_evidence_span, num_female_evidence_span, num_total_evidence_span\n",
    "- num_white, num_black, num_latino, num_asian, race_evidence_span\n",
    "\n",
    "Targets:\n",
    "- 'participants___male', 'participants___female', 'participants___total'\n",
    "- 'participants___white', 'participants___black', 'participants___latino', 'participants___asian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = df['paper___raw_text'].notna()\n",
    "texts = df[idxs]['paper___raw_text'].tolist()\n",
    "extractions = extraction.extract_nums_df(texts)\n",
    "for k in extractions.keys():\n",
    "    df.loc[idxs, k] = extractions[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "Evaluates whether each extracted number is within 1 of the human-labeled value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply some postprocessing to the predictions (convert percentages)\n",
    "gender_count_processed = df.apply(eval_extraction.process_gender_counts, axis=1)\n",
    "df[\"num_male\"] = gender_count_processed.apply(lambda x: x[0]).astype(str)\n",
    "df[\"num_female\"] = gender_count_processed.apply(lambda x: x[1]).astype(str)\n",
    "# print(\"Total n (with paper text)\", idxs.sum())\n",
    "eval_extraction.compute_metrics_within_1(\n",
    "    df,\n",
    "    preds_col_to_gt_col_dict={\n",
    "        \"num_male\": \"participants___male\",\n",
    "        \"num_female\": \"participants___female\",\n",
    "        \"num_total\": \"participants___total\",\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
