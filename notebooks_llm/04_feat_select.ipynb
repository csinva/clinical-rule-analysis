{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import imodels\n",
    "import eval_feat_select\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "import dvu\n",
    "import imodelsx\n",
    "import imodelsx.viz\n",
    "import imodelsx.llm\n",
    "from pprint import pprint\n",
    "import feat_select\n",
    "import viz_feat_select\n",
    "\n",
    "import openai\n",
    "openai.api_key_path = '/home/chansingh/.OPENAI_KEY'\n",
    "dvu.set_style()\n",
    "outcome = 'csi' # 'iai-i', 'tbi_young', 'tbi_old'\n",
    "dset_dict = feat_select.DSET_DICTS[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SITE', 'Predisposed', 'AxialLoadAnyDoc', 'axialloadtop', 'IsEms',\n",
       "       'Position_IDEMS', 'Position_L', 'Position_PA', 'Position_S',\n",
       "       'Position_W', 'Immobilization2', 'MedsRecd2', 'ArrPtIntub2',\n",
       "       'AgeInYears', 'gender_F', 'LOC_0.0', 'LOC_1.0', 'ambulatory_0.0',\n",
       "       'ambulatory_1.0', 'HighriskDiving_0.0', 'HighriskDiving_1.0',\n",
       "       'HighriskFall_0.0', 'HighriskFall_1.0', 'HighriskHanging_0.0',\n",
       "       'HighriskHanging_1.0', 'HighriskHitByCar_0.0',\n",
       "       'HighriskHitByCar_1.0', 'HighriskMVC_0.0', 'HighriskMVC_1.0',\n",
       "       'HighriskOtherMV_0.0', 'HighriskOtherMV_1.0', 'Clotheslining_0.0',\n",
       "       'Clotheslining_1.0', 'AlteredMentalStatus2_0.0',\n",
       "       'AlteredMentalStatus2_1.0', 'FocalNeuroFindings2_0.0',\n",
       "       'FocalNeuroFindings2_1.0', 'PainNeck2_0.0', 'PainNeck2_1.0',\n",
       "       'PosMidNeckTenderness2_0.0', 'PosMidNeckTenderness2_1.0',\n",
       "       'TenderNeck2_0.0', 'TenderNeck2_1.0', 'Torticollis2_0.0',\n",
       "       'Torticollis2_1.0', 'SubInjHead2_0.0', 'SubInjHead2_1.0',\n",
       "       'SubInjFace2_0.0', 'SubInjFace2_1.0', 'SubInjExt2_0.0',\n",
       "       'SubInjExt2_1.0', 'SubInjTorsoTrunk2_0.0', 'SubInjTorsoTrunk2_1.0',\n",
       "       'PtCompPainHead2_0.0', 'PtCompPainHead2_1.0',\n",
       "       'PtCompPainFace2_0.0', 'PtCompPainFace2_1.0', 'PtCompPainExt2_0.0',\n",
       "       'PtCompPainExt2_1.0', 'PtCompPainTorsoTrunk2_0.0',\n",
       "       'PtCompPainTorsoTrunk2_1.0', 'PtTenderHead2_0.0',\n",
       "       'PtTenderHead2_1.0', 'PtTenderFace2_0.0', 'PtTenderFace2_1.0',\n",
       "       'PtTenderExt2_0.0', 'PtTenderExt2_1.0', 'PtTenderTorsoTrunk2_0.0',\n",
       "       'PtTenderTorsoTrunk2_1.0'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, feats_raw = imodels.get_clean_dataset(\"csi_pecarn_prop\", data_source=\"imodels\")\n",
    "feats_raw = pd.Series(feats_raw)\n",
    "# df = pd.DataFrame(X, columns=feats_raw)\n",
    "\n",
    "# remove specific features\n",
    "idxs = feats_raw.str.endswith(\"_nan\")\n",
    "# idxs |= feats_raw.isin(['AgeTwoPlus', 'AgeInMonth'])\n",
    "# for k in ['LtCostalTender', 'RtCostalTender']:\n",
    "# idxs |= feats_raw.str.startswith(k)\n",
    "\n",
    "# apply\n",
    "# X = X[:, ~idxs]\n",
    "feats_raw = feats_raw[~idxs]\n",
    "# feats_abbrev_unique = set(feats_raw.apply(raw_to_abbrev))\n",
    "\n",
    "# return X, y, feats_raw, feats_abbrev_unique\n",
    "feats_raw.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feats_raw, feats_abbrev_unique = dset_dict['get_data'](outcome=outcome)\n",
    "print(f\"Unique features: {len(feats_abbrev_unique)}\", 'X shape', X.shape)\n",
    "print('Positive outcomes', y.sum())\n",
    "\n",
    "# # plt.figure(figsize=(8, 12))\n",
    "# # n = df_full.shape[1] - 1\n",
    "# # plt.barh(y=np.arange(n), width=df_full.corr()[\"outcome\"][:-1])\n",
    "# # plt.yticks(np.arange(n), pd.Series(df_full.columns[:-1]).apply(lambda x: x[:20]))\n",
    "# # plt.grid()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "# feats_select = rng.choice(list(feats_abbrev_unique), size=5, replace=False)\n",
    "# feats_select = ['AbdTrauma']\n",
    "feats_select = dset_dict['pecarn_feats_ordered']\n",
    "idxs_raw = feat_select.abbrevs_to_idxs_raw(feats_select, feats_raw)\n",
    "\n",
    "mets = eval_feat_select.evaluate_features(\n",
    "    X[:, idxs_raw], y, seed=42, class_weight=2, return_pr_curve=True\n",
    ")\n",
    "prec, rec, thresh = mets['roc_auc_curve']\n",
    "plt.plot(rec, prec, '.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mets_avg(strategies, feats_abbrev_unique, X, y, dset_dict, num_seeds=2):\n",
    "    \"\"\"Compute metrics when fitting a simple classifier\n",
    "    using features selected from feats_abbrev_unique\n",
    "    \"\"\"\n",
    "    mets_list_strategies = defaultdict(list)\n",
    "    for strategy in tqdm(strategies):\n",
    "        for seed in range(num_seeds):\n",
    "            mets_seed = defaultdict(list)\n",
    "            feats_ordered = feat_select.get_feats_ordered(\n",
    "                feats_abbrev_unique, dset_dict, strategy=strategy, seed=seed\n",
    "            )\n",
    "            for i in range(len(feats_ordered)):\n",
    "                feats_select = feats_ordered[: i + 1]\n",
    "                idxs_raw = feat_select.abbrevs_to_idxs_raw(feats_select, feats_raw)\n",
    "                met_scores = eval_feat_select.evaluate_features(\n",
    "                    X[:, idxs_raw], y, seed=42 + seed\n",
    "                )\n",
    "                for k in met_scores:\n",
    "                    mets_seed[k].append(met_scores[k])\n",
    "                mets_seed[\"n_feats\"].append(i + 1)\n",
    "            mets_list_strategies[strategy].append(pd.DataFrame(mets_seed))\n",
    "\n",
    "    # average over seed: convert mets_list_strategies to mets_avg\n",
    "    mets_avg = defaultdict(list)\n",
    "    for strategy in strategies:\n",
    "        m = mets_list_strategies[strategy]\n",
    "        cols = m[0].columns\n",
    "        mets_mean = pd.DataFrame(\n",
    "            data=np.mean([m[i].values for i in range(len(m))], axis=0),\n",
    "            columns=cols,\n",
    "        )\n",
    "        mets_sem = pd.DataFrame(\n",
    "            data=np.std([m[i].values for i in range(len(m))], axis=0) / np.sqrt(len(m)),\n",
    "            columns=[k + \"_sem\" for k in cols],\n",
    "        )\n",
    "        mets_avg[strategy] = pd.concat([mets_mean, mets_sem], axis=1)\n",
    "\n",
    "    return mets_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possibly-memorized plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mets_avg = compute_mets_avg(\n",
    "    [\"gpt-4-0314\", \"pecarn\", \"random\"],  # , \"pecarn___gpt-4-0314\"],\n",
    "    feats_abbrev_unique,\n",
    "    X,\n",
    "    y,\n",
    "    dset_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_feat_select.viz_curves(\n",
    "    mets_avg,\n",
    "    strategies=[\"pecarn\", \"gpt-4-0314\", \"random\"],\n",
    "    outcome=outcome,\n",
    "    n_end=len(dset_dict[\"pecarn_feats_ordered\"]),\n",
    "    n_pecarn=len(dset_dict[\"pecarn_feats_ordered\"]),\n",
    ")\n",
    "plt.savefig(f\"../results_llm/{outcome}_reselect_original.pdf\")\n",
    "# viz_feat_select.viz_curves(mets_avg, strategies=['gpt-4-0314', 'random'], outcome=outcome, n_end=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolating to new features plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [\"gpt-4-0314\", \"random\"]\n",
    "mets_avg = compute_mets_avg(\n",
    "    strategies,\n",
    "    [\n",
    "        feat\n",
    "        for feat in feats_abbrev_unique\n",
    "        if not feat in dset_dict[\"pecarn_feats_ordered\"]\n",
    "    ],\n",
    "    X,\n",
    "    y,\n",
    "    dset_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_feat_select.viz_curves(mets_avg, strategies=strategies, outcome=outcome, n_start=8-1)\n",
    "plt.savefig(f'../results_llm/{outcome}_reselect_unused.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
