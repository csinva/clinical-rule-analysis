{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import imodelsx.llm\n",
    "import numpy as np\n",
    "import paper_setup\n",
    "import paper_parsing\n",
    "import openai\n",
    "import eval\n",
    "openai.api_key = open('/home/chansingh/.OPENAI_KEY').read().strip()\n",
    "imodelsx.llm.LLM_CONFIG['LLM_REPEAT_DELAY'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load df with groundtruth values and paper ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_setup.download_open_source_papers(df) \n",
    "# need to first download papers from https://drive.google.com/drive/folders/1OUXtsddxEAOl3tKEZegBQSwArUecb-6J into ../papers\n",
    "df, ids_with_paper = paper_setup.download_gsheet()\n",
    "\n",
    "# export missing papers\n",
    "# cols = ['id', 'ref_text', 'ref_href']\n",
    "# idx = df['found_paper (0=no, 1=yes)'] == '0'\n",
    "# df[idx][cols].to_csv('missing_papers.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract info from the pdfs -- add values to the following columns:\n",
    "- num_male, num_female, num_total, num_male_evidence_span, num_female_evidence_span, num_total_evidence_span\n",
    "- num_white, num_black, num_latino, num_asian, race_evidence_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_parsing.extract_nums_and_add_to_df(df, ids_with_paper, extract_texts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "Evaluates whether each extracted number is within 1 of the human-labeled value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total n 537\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>recall</th>\n",
       "      <th>n_labeled</th>\n",
       "      <th>n_predicted_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_male</td>\n",
       "      <td>192</td>\n",
       "      <td>221</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_female</td>\n",
       "      <td>192</td>\n",
       "      <td>221</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_total</td>\n",
       "      <td>219</td>\n",
       "      <td>259</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  recall  n_labeled  n_predicted_num\n",
       "0    num_male     192        221              254\n",
       "1  num_female     192        221              257\n",
       "2   num_total     219        259              384"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_count_processed = df.apply(eval.process_gender_counts, axis=1)\n",
    "df[\"num_male\"] = gender_count_processed.apply(lambda x: x[0]).astype(str)\n",
    "df[\"num_female\"] = gender_count_processed.apply(lambda x: x[1]).astype(str)\n",
    "\n",
    "# view metrics in DataFrame d\n",
    "print(\"total n\", len(ids_with_paper))\n",
    "eval.compute_metrics(df, columns_without_corrected=[\"num_male\", \"num_female\", \"num_total\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final process and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 537/537 [00:00<00:00, 1172.82it/s]\n"
     ]
    }
   ],
   "source": [
    "df = paper_parsing.check_race_keywords(df, ids_with_paper)\n",
    "df[\"paper_contains_race_keywords\"].sum()\n",
    "# convert columns to int\n",
    "cols_int = [\"ref_year\", \"found_paper (0=no, 1=yes)\", \"paper_contains_race_keywords\"]\n",
    "for c in cols_int:\n",
    "    df[c] = df[c].apply(eval.int_or_neg1)\n",
    "df = df.sort_values(\n",
    "    by=[\"found_paper (0=no, 1=yes)\", \"paper_contains_race_keywords\", \"ref_year\", \"id\"],\n",
    "    ascending=False,\n",
    ")\n",
    "df.to_csv(\"../data/main.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
