{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import dvu\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import os.path\n",
    "import fitz\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import imodelsx.llm\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import openai\n",
    "openai.api_key = open('/home/chansingh/.OPENAI_KEY').read().strip()\n",
    "plt.style.use('default')\n",
    "dvu.set_style()\n",
    "\n",
    "df = pd.read_csv('../data/main_updated.csv')\n",
    "df = df[df['id'].notna()]\n",
    "\n",
    "# extract text from pdfs\n",
    "d = df[\n",
    "    (df[\"found_paper (0=no, 1=yes, 2=low-qual)\"] == 1)\n",
    "    | (df[\"found_paper (0=no, 1=yes, 2=low-qual)\"] == 2)\n",
    "]\n",
    "d.index = np.arange(d.shape[0])\n",
    "for i, row in tqdm(d.iterrows()):\n",
    "    paper_file = join(\"../papers\", str(row.id) + \".pdf\")\n",
    "    if pathlib.Path(paper_file).exists():\n",
    "        with fitz.open(paper_file) as doc:  # open document\n",
    "            text = chr(12).join([page.get_text() for page in doc])\n",
    "            text = text.replace('-\\n', '')\n",
    "            pathlib.Path(join(\"../papers\", str(row.id) + \".txt\")).write_bytes(\n",
    "                text.encode()\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask questions about the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = imodelsx.llm.get_llm(\"gpt-3.5-turbo-0613\")\n",
    "llm = imodelsx.llm.get_llm(\"gpt-4-0613\")\n",
    "# llm = imodelsx.llm.get_llm(\"gpt-4-32k-0613\")\n",
    "# gpt-4-32k-0613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {\n",
    "    \"num_male\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The number of male patients in the study\",\n",
    "    },\n",
    "    \"num_female\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The number of female patients in the study\",\n",
    "    },\n",
    "    \"num_male_evidence_span\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The long text span in the input that includes evidence for num_male.\",\n",
    "    },\n",
    "    \"num_female_evidence_span\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The long text span in the input that includes evidence for num_female.\",\n",
    "    },\n",
    "    \"num_white\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The number of white/caucasian patients in the study\",\n",
    "    },\n",
    "    \"num_black\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The number of black/african american patients in the study\",\n",
    "    },\n",
    "    \"num_latino\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The number of latino patients in the study\",\n",
    "    },\n",
    "    \"num_white_evidence_span\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The long text span in the input that includes evidence for num_white.\",\n",
    "    },\n",
    "    \"num_black_evidence_span\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The long text span in the input that includes evidence for num_black.\",\n",
    "    },\n",
    "    \"num_latino_evidence_span\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The long text span in the input that includes evidence for num_latino.\",\n",
    "    },\n",
    "}\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"extract_patient_nums\",\n",
    "        \"description\": \"Get the number of patients in this study for each gender and race.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": properties,\n",
    "            \"required\": [\n",
    "                \"num_male\",\n",
    "                \"num_female\",\n",
    "                \"num_male_evidence_span\",\n",
    "                \"num_female_evidence_span\",\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "content_str = \"\"\"### QUESTION: How many male and female patients were in this study?\n",
    "\n",
    "###  STUDY: {input}\"\"\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": content_str,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with answer: One hundred and five patients, 55 males and 50 females\n",
    "toy_input1 = \"\"\"This study was about treating diabetes. It was a very difficult study.\n",
    "One hundred and five patients, 55 males and 50 females were included.\n",
    "The study took 200 days to complete. The study was conducted in the United States.\n",
    "The study was conducted by the University of California, San Francisco.\"\"\"\n",
    "\n",
    "# example with answer: One hundred and five patients, 55 males and 50 females, 10 white, 75 black\n",
    "toy_input2 = \"\"\"This study was about treating diabetes. It was a very difficult study.\n",
    "One hundred and five patients, 55 males and 50 females were included.\n",
    "The study took 200 days to complete. The study was conducted in the United States.\n",
    "Ten of the patients were white, 20 were asian, and the rest were black.\n",
    "The study was conducted by the University of California, San Francisco.\"\"\"\n",
    "\n",
    "# messages[0]['content'] = content_str.format(input=toy_input1)\n",
    "# msg = llm(messages, functions=functions, return_str=False, temperature=0.0)\n",
    "# args = json.loads(msg.get('function_call')['arguments'])\n",
    "# print(json.dumps(args, indent=2))\n",
    "\n",
    "# messages[0]['content'] = content_str.format(input=toy_input2)\n",
    "# msg = llm(messages, functions=functions, return_str=False, temperature=0.0)\n",
    "# args = json.loads(msg.get('function_call')['arguments'])\n",
    "# print(json.dumps(args, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in properties.keys():\n",
    "    d[k] = None\n",
    "d[\"approx_tokens\"] = None\n",
    "for i in range(d.shape[0]):\n",
    "    row = d.iloc[i]\n",
    "    paper_file = join(\"../papers\", str(int(row.id)) + \".txt\")\n",
    "    # example with answer: One hundred and five patients, 55 males and 50 females\n",
    "    real_input = pathlib.Path(paper_file).read_text()\n",
    "    approx_tokens = len(real_input) / 4\n",
    "    print(\n",
    "        \"approx tokens\", approx_tokens\n",
    "    )  # gpt4 has 8k token window (some of it is functions, etc.)\n",
    "    real_input = real_input[: 5000 * 4]\n",
    "    d.loc[d.index[i], \"approx_tokens\"] = approx_tokens\n",
    "\n",
    "    # if approx_tokens < 6000:\n",
    "    messages[0][\"content\"] = content_str.format(input=real_input)\n",
    "    try:\n",
    "        msg = llm(messages, functions=functions, return_str=False, temperature=0.0)\n",
    "        args = json.loads(msg.get(\"function_call\")[\"arguments\"])\n",
    "        print(json.dumps(args, indent=2))\n",
    "        for k in properties.keys():\n",
    "            if k in args:\n",
    "                # set the value at row number i and column k to the value of args[k]\n",
    "                d.loc[d.index[i], k] = args[k]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "print('completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_evidence(ev: str, real_input: str):\n",
    "    if ev is not None:\n",
    "        # remove all whitespace\n",
    "        ev = \"\".join(ev.split())\n",
    "        real_input = \"\".join(real_input.split())\n",
    "        return ev.lower() in real_input.lower()\n",
    "    return False\n",
    "\n",
    "# check evidence\n",
    "for i in range(d.shape[0]):\n",
    "    row = d.iloc[i]\n",
    "    paper_file = join(\"../papers\", str(int(row.id)) + \".txt\")\n",
    "    real_input = pathlib.Path(paper_file).read_text()\n",
    "    for k in [\"num_male_evidence_span\", \"num_female_evidence_span\"]:\n",
    "        ev = row[k]\n",
    "        if ev is not None:\n",
    "            print(row.id, 'contained', check_evidence(ev, real_input))\n",
    "            print('\\t', ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"num_male\",\n",
    "        \"num_female\",\n",
    "        \"num_male_evidence_span\",\n",
    "        \"num_female_evidence_span\",\n",
    "    ]\n",
    "].to_csv(\"../data/gender_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
