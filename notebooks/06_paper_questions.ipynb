{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import dvu\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import imodelsx.llm\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import openai\n",
    "import pubmed\n",
    "import prompts\n",
    "openai.api_key = open('/home/chansingh/.OPENAI_KEY').read().strip()\n",
    "plt.style.use('default')\n",
    "dvu.set_style()\n",
    "\n",
    "df = pd.read_csv('../data/main.csv')\n",
    "\n",
    "# extract text from pdfs\n",
    "ids_with_paper = df[df[\"found_paper (0=no, 1=yes)\"] > 0].id.astype(int).values\n",
    "# print(len(ids_with_paper), ids_with_paper.values)\n",
    "\n",
    "# get papers\n",
    "ids_found = sorted(\n",
    "    [int(x.replace(\".pdf\", \"\")) for x in os.listdir(\"../papers\") if x.endswith(\".pdf\")]\n",
    ")\n",
    "\n",
    "for paper_id in ids_with_paper:\n",
    "    if paper_id in ids_found:\n",
    "        continue\n",
    "    else:\n",
    "        print('should have paper', paper_id)\n",
    "\n",
    "for paper_id in ids_found:\n",
    "    if paper_id in ids_with_paper:\n",
    "        continue\n",
    "    else:\n",
    "        print(paper_id, 'in local pdfs but not in main.csv')\n",
    "        idx = df[df.id == paper_id].index[0]\n",
    "        print(df.loc[idx, 'found_paper (0=no, 1=yes)'])\n",
    "        df.loc[idx, 'found_paper (0=no, 1=yes)'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download papers\n",
    "# refs = pubmed.get_updated_refs(df)\n",
    "# all_ids = df.id\n",
    "# ids_missing = [str(id) for id in all_ids if id not in ids_found]\n",
    "# pmids_missing = {}\n",
    "# for id in ids_missing:\n",
    "#     ref = refs[df[\"id\"] == int(id)][0]\n",
    "    \n",
    "#     if isinstance(ref, str) and 'pubmed' in ref:\n",
    "#         paper_id = pubmed.get_paper_id(ref)\n",
    "#         # print(id, ref, paper_id)\n",
    "#         pmids_missing[paper_id] = id\n",
    "# s = \",\".join(list(pmids_missing.keys()))\n",
    "# # !python -m pubmed2pdf pdf --pmids=\"{s}\"\n",
    "\n",
    "# # rename each pdf file in pubmed2pdf to its id\n",
    "# pubmed_papers_dir = pathlib.Path(\"../pubmed2pdf\")\n",
    "# papers_downloaded = os.listdir(pubmed_papers_dir)\n",
    "# for paper in papers_downloaded:\n",
    "#     paper_id = paper.split(\".\")[0]\n",
    "#     paper_id = pmids_missing[paper_id]\n",
    "#     os.rename(\n",
    "#         join(pubmed_papers_dir, paper),\n",
    "#         join(pubmed_papers_dir, f\"{paper_id}.pdf\"),\n",
    "#     )\n",
    "pubmed.extract_texts_from_pdf(ids_with_paper)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask questions about the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = imodelsx.llm.get_llm(\"gpt-3.5-turbo-0613\")\n",
    "llm = imodelsx.llm.get_llm(\"gpt-4-0613\")\n",
    "# llm = imodelsx.llm.get_llm(\"gpt-4-32k-0613\")\n",
    "\n",
    "# properties, functions, content_str = prompts.get_prompts_demographics()\n",
    "properties, functions, content_str = prompts.get_prompts_gender()\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": content_str,\n",
    "    }\n",
    "]\n",
    "\n",
    "# example with answer: One hundred and five patients, 55 males and 50 females\n",
    "toy_input1 = \"\"\"This study was about treating diabetes. It was a very difficult study.\n",
    "One hundred and five patients, 55 males and 50 females were included.\n",
    "The study took 200 days to complete. The study was conducted in the United States.\n",
    "The study was conducted by the University of California, San Francisco.\"\"\"\n",
    "\n",
    "# example with answer: One hundred and five patients, 55 males and 50 females, 10 white, 75 black\n",
    "toy_input2 = \"\"\"This study was about treating diabetes. It was a very difficult study.\n",
    "One hundred and five patients, 55 males and 50 females were included.\n",
    "The study took 200 days to complete. The study was conducted in the United States.\n",
    "Ten of the patients were white, 20 were asian, and the rest were black.\n",
    "The study was conducted by the University of California, San Francisco.\"\"\"\n",
    "\n",
    "# messages[0]['content'] = content_str.format(input=toy_input1)\n",
    "# msg = llm(messages, functions=functions, return_str=False, temperature=0.0)\n",
    "# args = json.loads(msg.get('function_call')['arguments'])\n",
    "# print(json.dumps(args, indent=2))\n",
    "\n",
    "# messages[0]['content'] = content_str.format(input=toy_input2)\n",
    "# msg = llm(messages, functions=functions, return_str=False, temperature=0.0)\n",
    "# args = json.loads(msg.get('function_call')['arguments'])\n",
    "# print(json.dumps(args, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 31/184 [02:43<18:46,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cached!\n",
      "'choices'\n"
     ]
    }
   ],
   "source": [
    "def rename_to_none(x: str):\n",
    "    if x in {\"\", \"unknown\", \"N/A\"}:\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def call_on_subsets(x: str, subset_len_tokens=4750, max_calls=3):\n",
    "    subset_len_chars = subset_len_tokens * 4\n",
    "\n",
    "    args = None\n",
    "    subset_num = 0\n",
    "\n",
    "    while args is None and subset_num < max_calls:\n",
    "        subset = x[subset_num * subset_len_chars : (subset_num + 1) * subset_len_chars]\n",
    "\n",
    "        # if approx_tokens < 6000:\n",
    "        messages[0][\"content\"] = content_str.format(input=subset)\n",
    "        msg = llm(messages, functions=functions, return_str=False, temperature=0.0)\n",
    "        if msg is not None and msg.get(\"function_call\") is not None:\n",
    "            args = json.loads(msg.get(\"function_call\")[\"arguments\"])\n",
    "            return args\n",
    "\n",
    "        subset_num += 1\n",
    "\n",
    "        # next segment should have atleast 0.5 * subset_len_chars_left\n",
    "        if len(x) < (subset_num + 0.5) * subset_len_chars:\n",
    "            break\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_evidence(ev: str, real_input: str):\n",
    "    if ev is not None:\n",
    "        # remove all whitespace\n",
    "        ev = \"\".join(ev.split())\n",
    "        real_input = \"\".join(real_input.split())\n",
    "        return ev.lower() in real_input.lower()\n",
    "    return False\n",
    "\n",
    "\n",
    "# initialize\n",
    "for k in properties.keys():\n",
    "    df.loc[:, k] = None\n",
    "# df[\"approx_tokens\"] = None\n",
    "\n",
    "# run loop\n",
    "for id in tqdm(ids_with_paper):\n",
    "    i = df[df.id == id].index[0]\n",
    "    row = df.iloc[i]\n",
    "    paper_file = join(\"../papers\", str(int(row.id)) + \".txt\")\n",
    "\n",
    "    try:\n",
    "        real_input = pathlib.Path(paper_file).read_text()\n",
    "        # gpt4 has 8k token window (some of it is functions, etc.)\n",
    "        # approx_tokens = (len(real_input) / 4)\n",
    "        # df.loc[i, \"approx_tokens\"] = approx_tokens\n",
    "        args = call_on_subsets(real_input)\n",
    "\n",
    "        # print(json.dumps(args, indent=2))\n",
    "        if args is not None:\n",
    "            for k in properties.keys():\n",
    "                if k in args:\n",
    "                    # set the value at row number i and column k to the value of args[k]\n",
    "                    df.loc[i, k] = rename_to_none(args[k])\n",
    "\n",
    "                    # remove spans if they are not actually contained in the text\n",
    "                    if k in [\"num_male_evidence_span\", \"num_female_evidence_span\"]:\n",
    "                        if not check_evidence(args[k], real_input):\n",
    "                            df.loc[i, k] = None\n",
    "    except Exception as e:\n",
    "        print(row.id, e)\n",
    "print(\"completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "\n",
    "for k in ['num_male', 'num_female']:\n",
    "    idxs = (df[k + '_corrected'].notnull() & ~(df[k + '_corrected'] == 'Unk'))\n",
    "    gt = df[k + '_corrected'][idxs].astype(int)\n",
    "    pred = df[k].apply(cast_int)[idxs].astype(int)\n",
    "    acc = (gt == pred).mean()\n",
    "    print(f'{k} acc={acc:0.2f} n={len(gt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/main.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at gender ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = (df['num_male_corrected'].notnull() & ~(df['num_male_corrected'] == 'Unk')) & (df['num_female_corrected'].notnull() & ~(df['num_female_corrected'] == 'Unk'))\n",
    "male = df['num_male_corrected'][idxs].astype(int)\n",
    "female = df['num_female_corrected'][idxs].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = (male / female).values\n",
    "# drop inf\n",
    "print(sorted(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 2), dpi=300)\n",
    "r = ratios[~np.isinf(ratios)]\n",
    "logr = np.log10(r)\n",
    "print('mean', r.mean(), 'frac>0', (r > 1).sum(), '/', len(r))\n",
    "plt.hist(logr[logr < 0], color='pink') #, bins=100)\n",
    "plt.hist(logr[logr >= 0], color='C0') #, bins=100)\n",
    "plt.axvline(0, color='black', ls='--')\n",
    "ticks = plt.xticks()[0]\n",
    "plt.xticks(ticks, [f'$10^{{{t}}}$' for t in ticks])\n",
    "plt.xlabel('Ratio (male / female)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
