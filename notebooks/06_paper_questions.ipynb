{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import dvu\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import os.path\n",
    "import fitz\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import imodelsx.llm\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import openai\n",
    "openai.api_key = open('/home/chansingh/.OPENAI_KEY').read().strip()\n",
    "plt.style.use('default')\n",
    "dvu.set_style()\n",
    "\n",
    "df = pd.read_csv('../data/main_updated.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df[\n",
    "    (df[\"found_paper (0=no, 1=yes, 2=low-qual)\"] == 1)\n",
    "    | (df[\"found_paper (0=no, 1=yes, 2=low-qual)\"] == 2)\n",
    "]\n",
    "for i, row in tqdm(d.iterrows()):\n",
    "    paper_file = join(\"../papers\", str(row.id) + \".pdf\")\n",
    "    if pathlib.Path(paper_file).exists():\n",
    "        with fitz.open(paper_file) as doc:  # open document\n",
    "            text = chr(12).join([page.get_text() for page in doc])\n",
    "            pathlib.Path(join(\"../papers\", str(row.id) + \".txt\")).write_bytes(\n",
    "                text.encode()\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask questions about the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = imodelsx.llm.get_llm(\"gpt-3.5-turbo-0613\")\n",
    "llm = imodelsx.llm.get_llm(\"gpt-4-0613\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_paper_study_distribution_by_gender\",\n",
    "        \"description\": \"Get the distribution of patients in this study accordong to gender\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"num_male\": {\n",
    "                    \"type\": \"int\",\n",
    "                    \"description\": \"The number of male patients in the study\",\n",
    "                },\n",
    "                \"num_female\": {\n",
    "                    \"type\": \"int\",\n",
    "                    \"description\": \"The number of female patients in the study\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"num_male\", \"num_female\"],\n",
    "        },\n",
    "    },\n",
    "\n",
    "]\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = llm(messages, functions=functions, return_str=False)\n",
    "print(msg.get('function_call'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
