{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import dvu\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import imodelsx.llm\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import openai\n",
    "import pubmed\n",
    "import paper_parsing\n",
    "import prompts\n",
    "openai.api_key = open('/home/chansingh/.OPENAI_KEY').read().strip()\n",
    "plt.style.use('default')\n",
    "dvu.set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load papers and extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubmed.download_open_source_papers(df) \n",
    "df, ids_with_paper = paper_parsing.download_and_check_gsheet()\n",
    "\n",
    "# extract text from pdfs (create file num.txt for each file num.pdf)\n",
    "# paper_parsing.extract_texts_from_pdf(ids_with_paper, papers_dir='../papers')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract info from the text (populate the predicted columns)\n",
    "- num_male, num_female, num_total, num_male_evidence_span, num_female_evidence_span, num_total_evidence_span\n",
    "- num_white, num_black, num_latino, num_asian, race_evidence_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempting to add dict_keys(['num_male', 'num_female', 'num_total', 'evidence_span_gender'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/184 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not cached\n"
     ]
    }
   ],
   "source": [
    "# get prompt\n",
    "llm = imodelsx.llm.get_llm(\"gpt-4-0613\") # gpt-3.5-turbo-0613\n",
    "imodelsx.llm.LLM_CONFIG['LLM_REPEAT_DELAY'] = 5\n",
    "\n",
    "\n",
    "# properties, functions, content_str = prompts.get_prompts_gender_and_race()\n",
    "# print('attempting to add', properties.keys())\n",
    "# paper_parsing.add_columns_based_on_properties(df, ids_with_paper, properties, functions, content_str, llm)\n",
    "\n",
    "properties, functions, content_str = prompts.get_prompts_gender()\n",
    "print('attempting to add', properties.keys())\n",
    "paper_parsing.add_columns_based_on_properties(df, ids_with_paper, properties, functions, content_str, llm)\n",
    "\n",
    "properties, functions, content_str = prompts.get_prompts_demographics()\n",
    "print('attempting to add', properties.keys())\n",
    "paper_parsing.add_columns_based_on_properties(df, ids_with_paper, properties, functions, content_str, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_male acc=0.81 n=62\n",
      "num_female acc=0.81 n=62\n"
     ]
    }
   ],
   "source": [
    "for k in ['num_male', 'num_female']:\n",
    "    idxs = (df[k + '_corrected'].notnull() & ~(df[k + '_corrected'] == 'Unk'))\n",
    "    gt = df[k + '_corrected'][idxs].astype(int)\n",
    "    pred = df[k].apply(paper_parsing.cast_int)[idxs].astype(int)\n",
    "    acc = (gt == pred).mean()\n",
    "    print(f'{k} acc={acc:0.2f} n={len(gt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/main.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
