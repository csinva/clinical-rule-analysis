{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import dvu\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import imodelsx.llm\n",
    "import os\n",
    "import numpy as np\n",
    "import pubmed\n",
    "import openai\n",
    "from mdcalc import try_or_none\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "openai.api_key = open('/home/chansingh/.OPENAI_KEY').read().strip()\n",
    "plt.style.use('default')\n",
    "dvu.set_style()\n",
    "llm = imodelsx.llm.get_llm(\n",
    "    checkpoint=\"gpt-3.5-turbo\",\n",
    "    CACHE_DIR=\"/home/chansingh/cache/pubmed_names\",\n",
    "    repeat_delay=1,\n",
    ")\n",
    "\n",
    "df = pd.read_csv('../data/main.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping pubmed articles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- E-utilities: https://dataguide.nlm.nih.gov/eutilities/utilities.html\n",
    "- Metadata: https://www.ncbi.nlm.nih.gov/pmc/tools/get-metadata/\n",
    "- example paper: https://pubmed.ncbi.nlm.nih.gov/16768059/\n",
    "- example summary: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&id=16768059&retmode=json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "df[\"ref_href\"] = pubmed.get_updated_refs(df)\n",
    "df[\"ref_metadata\"] = np.nan\n",
    "df[\"ref_authors\"] = np.nan\n",
    "df[\"ref_authors_full\"] = np.nan\n",
    "df[\"ref_authors_affils\"] = np.nan\n",
    "# df[\"ref_citations\"] = np.nan\n",
    "# df[\"ref_url_free_text\"] = np.nan\n",
    "\n",
    "# only keep pubmed links\n",
    "df_dropnan = df[\n",
    "    (df[\"ref_href\"].notna())\n",
    "    & ~(df[\"ref_href\"] == \"\")\n",
    "    & ~(df[\"ref_href_corrected\"] == \"Unk\")\n",
    "]\n",
    "df_dropnonpubmed = df_dropnan[df_dropnan[\"ref_href\"].str.contains(\"pubmed\")]\n",
    "df_dropnonpubmed.loc[:, \"paper_id\"] = df_dropnonpubmed[\"ref_href\"].apply(\n",
    "    pubmed.get_paper_id\n",
    ")\n",
    "print(\n",
    "    \"all cdis\",\n",
    "    df.shape[0],\n",
    "    \"drop na\",\n",
    "    df_dropnan.shape[0],\n",
    "    \"drop non pubmed\",\n",
    "    df_dropnonpubmed.shape[0],\n",
    ")\n",
    "df = df_dropnonpubmed  # .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run scraping (caches so is safe to rerun)\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    row = df.iloc[i]\n",
    "    paper_link = row[\"ref_href\"]\n",
    "    if isinstance(paper_link, str) and \"pubmed\" in paper_link:\n",
    "        # paper_link = 'https://pubmed.ncbi.nlm.nih.gov/20738765/'\n",
    "        paper_id = row['paper_id']\n",
    "\n",
    "        # this scrapes pubmed api\n",
    "        try:\n",
    "            metadata = pubmed.get_metadata(paper_id)\n",
    "            df[\"ref_metadata\"].iloc[i] = metadata\n",
    "            df[\"ref_authors\"].iloc[i] = metadata[\"result\"][paper_id][\"authors\"]\n",
    "            # df[\"ref_num_references\"][i] = metadata[\"result\"][paper_id][\"pmcrefcount\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error for paper {paper_id}\", e)\n",
    "\n",
    "        # this scrapes actual paper page\n",
    "        authors_list = pubmed.get_authors_with_firstname(paper_link, paper_id)\n",
    "        df[\"ref_authors_full\"].iloc[i] = [\n",
    "            pubmed.parse_name(name) for name in authors_list]\n",
    "        # print('auth_list', authors_list)\n",
    "        # except:\n",
    "        # print(f\"Error scraping for paper {paper_id}\")\n",
    "        df['ref_authors_affils'].iloc[i] = pubmed.get_author_affiliations(\n",
    "            paper_id)\n",
    "print('failed to scrape affils for',\n",
    "      df['ref_authors_affils'].isna().sum(), 'papers')\n",
    "print('successfully scraped for',\n",
    "      df['ref_authors_affils'].notna().sum(), 'papers')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_from_name(name: str):\n",
    "    return llm(\n",
    "        f'Return whether the name \"{name}\" is more common for a male or a female. Answer with one word, \"Male\" or \"Female\"',\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_male_fraction_from_list(names):\n",
    "    genders = pd.Series([get_gender_from_name(name) for name in names if name])\n",
    "    fems = genders.str.lower().str.contains(\"fem\")\n",
    "    genders[fems] = 'F'\n",
    "    genders[~fems] = 'M'\n",
    "    return genders.tolist()\n",
    "    # return 1 - np.mean(genders.str.lower().str.contains(\"fem\"))\n",
    "\n",
    "\n",
    "df[\"ref_authors_genders\"] = df[\"ref_authors_full\"].apply(\n",
    "    get_male_fraction_from_list)\n",
    "\n",
    "names = sorted(df[\"ref_authors_full\"].explode().dropna().tolist())\n",
    "genders = []\n",
    "gender_ans = [get_gender_from_name(name) for name in tqdm(names)]\n",
    "pd.Series(gender_ans).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affiliations of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_to_continent(country_name):\n",
    "    country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "    country_continent_code = pc.country_alpha2_to_continent_code(\n",
    "        country_alpha2)\n",
    "    country_continent_name = pc.convert_continent_code_to_continent_name(\n",
    "        country_continent_code\n",
    "    )\n",
    "    return country_continent_name\n",
    "\n",
    "\n",
    "def get_country(country_name: str):\n",
    "    return llm(\n",
    "        f\"\"\"Return the name of the country present in the following affiliation: {country_name}.\n",
    "Return only the name of the country.\"\"\",\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "\n",
    "affiliations = np.array(\n",
    "    sorted(df[\"ref_authors_affils\"].explode().dropna().tolist()))\n",
    "dfa = pd.DataFrame(affiliations, columns=[\"aff_orig\"])\n",
    "\n",
    "# automatically parse countries\n",
    "dfa[\"aff_auto\"] = dfa[\"aff_orig\"].apply(\n",
    "    lambda x: \"\".join([c for c in x.split(\",\")[-1] if c.isalpha()])\n",
    ")\n",
    "dfa[\"country_auto\"] = dfa[\"aff_auto\"].progress_apply(\n",
    "    try_or_none(lambda x: pycountry.countries.search_fuzzy(x)[0])\n",
    ")\n",
    "\n",
    "# fill in missing countries with llm\n",
    "dfa[\"aff_llm\"] = None\n",
    "idxs_na = dfa[\"country_auto\"].isna()\n",
    "dfa.loc[idxs_na, \"aff_llm\"] = dfa.loc[idxs_na, \"aff_orig\"].progress_apply(\n",
    "    lambda x: get_country(x)\n",
    ")\n",
    "\n",
    "# clean and output\n",
    "dfa[\"aff_llm\"] = dfa[\"aff_llm\"].apply(pubmed.clean_llm_country_output)\n",
    "\n",
    "# get country\n",
    "dfa[\"country_llm\"] = dfa[\"aff_llm\"].progress_apply(\n",
    "    try_or_none(lambda x: pycountry.countries.search_fuzzy(x)[0])\n",
    ")\n",
    "dfa[\"country\"] = dfa[\"country_auto\"].fillna(dfa[\"country_llm\"])\n",
    "\n",
    "# get continents\n",
    "n = dfa[\"country\"].dropna().shape[0]\n",
    "print(\"dropping\", dfa.shape[0] - n, \"affiliations\",\n",
    "      \"resulting in\", n, \"affiliations\")\n",
    "countries = dfa[\"country\"].dropna()\n",
    "continents = countries.apply(lambda x: country_to_continent(x.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(continents.value_counts() / n *\n",
    "             100).transpose().style.hide(axis='index').format(\"{:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pd.DataFrame(countries.value_counts().head(15) / n * 100).reset_index()\n",
    "cv['country'] = cv['country'].apply(lambda x: x.name)\n",
    "cv.index = cv['country']\n",
    "cv = cv.drop('country', axis=1)\n",
    "cv.T.style.hide(axis='index').format(\"{:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story country in dataframe\n",
    "aff_to_country = {\n",
    "    aff: country for aff, country in zip(dfa[\"aff_orig\"], dfa[\"country\"]) if country\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_countries_from_list(l):\n",
    "    if l and len(l):\n",
    "        countries = []\n",
    "        for aff in l:\n",
    "            country = aff_to_country.get(aff, None)\n",
    "            if country:\n",
    "                countries.append(country.name)\n",
    "            else:\n",
    "                countries.append(None)\n",
    "        return countries\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "df[\"ref_authors_countries\"] = df[\"ref_authors_affils\"].apply(\n",
    "    get_countries_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"../data/main.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df[[col for col in df.columns if col.startswith(\"ref\")] + [\"id\"]]\n",
    "d_merged_refs = df_full[[\"id\"]].merge(\n",
    "    d[\n",
    "        [\n",
    "            \"id\",\n",
    "            \"ref_authors_full\",\n",
    "            \"ref_authors_affils\",\n",
    "            \"ref_authors_genders\",\n",
    "            \"ref_authors_countries\",\n",
    "        ]\n",
    "    ],\n",
    "    how=\"left\",\n",
    ")\n",
    "d_merged_refs.to_pickle('../data/cdis_with_author_affil.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any element of a list is not None\n",
    "def any_not_none(l):\n",
    "    for x in l:\n",
    "        if x is not None:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def count_male(authors_full):\n",
    "    if isinstance(authors_full, list) and any_not_none(authors_full):\n",
    "        return np.sum([get_gender_from_name(name) == \"Male.\" for name in authors_full])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def count_female(authors_full):\n",
    "    if isinstance(authors_full, list) and any_not_none(authors_full):\n",
    "        return np.sum([get_gender_from_name(name) == \"Female.\" for name in authors_full])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df[\"count_male\"] = df.apply(\n",
    "    lambda row: count_male(row[\"ref_authors_full\"]),\n",
    "    axis=1,\n",
    ")\n",
    "df['count_female'] = df.apply(\n",
    "    lambda row: count_female(row[\"ref_authors_full\"]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "dp = df.sort_values(by='ref_year')\n",
    "dp['count_male'].value_counts()\n",
    "# plt.plot(dp['ref_year'], np.cumsum(dp['count_male']))\n",
    "# plt.plot(dp['ref_year'], np.cumsum(dp['count_female']))\n",
    "plt.plot(dp['ref_year'], np.cumsum(dp['count_male']) /\n",
    "         np.cumsum(dp['count_female']))\n",
    "plt.grid()\n",
    "plt.xlim(2000, 2023)\n",
    "plt.ylim(2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up gender evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_cols = ['ref_authors_full', 'ref_authors_affils', 'ref_authors_genders']\n",
    "dd = defaultdict(list)\n",
    "for i in range(df.shape[0]):\n",
    "    row = df.iloc[i]\n",
    "    if row.ref_authors_full is not None and row.ref_authors_affils is not None:\n",
    "        authors = [a for a in row.ref_authors_full if not a is None]\n",
    "        author_refs = [r for r in row.ref_authors_affils if not r is None]\n",
    "        author_genders = row.ref_authors_genders\n",
    "        # print('lens', len(authors), len(author_refs), len(author_genders))\n",
    "        if len(authors) == len(author_refs) and len(author_refs) == len(author_genders):\n",
    "            dd['ref_authors_full'].append(authors)\n",
    "            dd['ref_authors_affils'].append(author_refs)\n",
    "            dd['ref_authors_genders'].append(author_genders)\n",
    "        elif len(authors) == len(author_genders) and len(author_refs) == 1:\n",
    "            dd['ref_authors_full'].append(authors)\n",
    "            dd['ref_authors_affils'].append(author_refs * len(authors))\n",
    "            dd['ref_authors_genders'].append(author_genders)\n",
    "\n",
    "dd = pd.DataFrame(dd)\n",
    "dd = dd.explode(author_cols)\n",
    "d1 = dd[dd.ref_authors_genders == 'M'].sample(700).reset_index()\n",
    "d2 = dd[dd.ref_authors_genders == 'F'].sample(700).reset_index()\n",
    "# interleave rows of d1/d2\n",
    "d = pd.concat([d1, d2]).sort_index(kind='merge')\n",
    "d['query'] = d.apply(\n",
    "    lambda row: f'https://www.google.com/search?q={\"+\".join(row.ref_authors_full.split())}+.homepage.{\"+\".join(row.ref_authors_affils.split())}', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('author_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.read_csv('../data/author_genders.csv')\n",
    "idxs = out['gt'] != 'X'\n",
    "o2 = out[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searched for 150 found gendered pronouns for 81\n",
      "correct 80 gt M: 41\n"
     ]
    }
   ],
   "source": [
    "print('searched for', idxs.shape[0],\n",
    "      'found gendered pronouns for', o2.shape[0])\n",
    "print('correct', (o2['gt'] == o2['pred']).sum(),\n",
    "      'gt M:', (o2['gt'] == 'M').sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
